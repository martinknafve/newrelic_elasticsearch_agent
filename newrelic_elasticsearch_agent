#!/usr/bin/env ruby

require 'rubygems'
require 'bundler/setup'
require 'newrelic_plugin'
require 'net/http'
require 'uri'
require 'socket'
require 'json'
require 'openssl'

module ElasticsearchStatsAgent

  class Agent < NewRelic::Plugin::Agent::Base

    agent_guid 'com.martinknafve.newrelic-elasticsearch-agent'
    agent_version '0.0.1'
    agent_config_options :name, :url, :index, :username, :password
    agent_human_labels('ElasticSearch') { name }

    def setup_metrics
      @indexing_index_rate = NewRelic::Processor::EpochCounter.new
      @indexing_delete_rate = NewRelic::Processor::EpochCounter.new
      @get_rate = NewRelic::Processor::EpochCounter.new
      @get_exists_rate = NewRelic::Processor::EpochCounter.new
      @get_missing_rate = NewRelic::Processor::EpochCounter.new
      @search_query_rate = NewRelic::Processor::EpochCounter.new
      @search_fetch_rate = NewRelic::Processor::EpochCounter.new
    end

    def poll_cycle
      unless get_elasticsearch_status
        return nil
      end


      clusterHealth = JSON.parse(get_elasticsearch_cluster_status)
	  report_metric "Cluster/ActivePrimaryShards",          "Count",        clusterHealth["active_primary_shards"]         if clusterHealth["active_primary_shards"]
	  report_metric "Cluster/ActiveShards",          		"Count",        clusterHealth["active_shards"]         if clusterHealth["active_shards"]
	  report_metric "Cluster/RelocatingShards",          	"Count",        clusterHealth["relocating_shards"]         if clusterHealth["relocating_shards"]
	  report_metric "Cluster/InitializingShards",           "Count",        clusterHealth["initializing_shards"]         if clusterHealth["initializing_shards"]
	  report_metric "Cluster/UnassignedShards",           "Count",        clusterHealth["unassigned_shards"]         if clusterHealth["unassigned_shards"]

      json = JSON.parse(get_elasticsearch_status)
      
      shards = json["_shards"]
	  report_metric "Shards/Total",          "Count",        shards["total"]                                               if shards["total"]
	  report_metric "Shards/Successful",     "Count",        shards["successful"]                                     if shards["successful"]
	  report_metric "Shards/Failed",         "Count",        shards["failed"]                                             if shards["failed"]

      if index == "_all"
        stats = json["_all"]
      else
        stats = json["indices"]["#{index}"] if json.has_key?("indices")
        stats = json["_all"]["indices"]["#{index}"] if json["_all"].has_key?("indices")
      end
      total = stats["total"] ||= Hash.new

      if total["docs"]
        report_metric "Documents/Count",          "Documents",        total["docs"]["count"]                                              if total["docs"]["count"]
        report_metric "Documents/Deleted",        "Documents",        total["docs"]["deleted"]                                            if total["docs"]["deleted"]
      end

      if total["store"]
        report_metric "Store/Size",               "MegaBytes",        total["store"]["size_in_bytes"] / 1024 / 1024                       if total["store"]["size_in_bytes"]
        report_metric "Store/Throttle",           "Seconds",          total["store"]["throttle_time_in_millis"] / 1000                    if total["store"]["throttle_time_in_millis"]
      end

      if total["indexing"]
        report_metric "Indexing/Index/Total",     "Indexes",          total["indexing"]["index_total"]                                    if total["indexing"]["index_total"]
        report_metric "Indexing/Index/Time",      "Milliseconds",     total["indexing"]["index_time_in_millis"]                           if total["indexing"]["index_time_in_millis"]
        report_metric "Indexing/Index/Rate",      "Indexes/sec",      @indexing_index_rate.process(total["indexing"]["index_total"])      if total["indexing"]["index_total"]
        report_metric "Indexing/Delete/Total",    "Deletes",          total["indexing"]["delete_total"]                                   if total["indexing"]["delete_total"]
        report_metric "Indexing/Delete/Time",     "Milliseconds",     total["indexing"]["delete_time_in_millis"]                          if total["indexing"]["delete_time_in_millis"]
        report_metric "Indexing/Delete/Rate",     "Deletes/sec",      @indexing_delete_rate.process(total["indexing"]["delete_total"])    if total["indexing"]["delete_total"]
      end

      if total["get"]
        report_metric "Get/Total",                "Queries",          total["get"]["total"]                                               if total["get"]["total"]
        report_metric "Get/Time",                 "Milliseconds",     total["get"]["time_in_millis"]                                      if total["get"]["time_in_millis"]
        report_metric "Get/Rate",                 "Queries/sec",      @get_rate.process(total["get"]["total"])                            if total["get"]["total"]
        report_metric "Get/Exists/Total",         "Exists",           total["get"]["exists_total"]                                        if total["get"]["exists_total"]
        report_metric "Get/Exists/Time",          "Milliseconds",     total["get"]["exists_time_in_millis"]                               if total["get"]["exists_time_in_millis"]
        report_metric "Get/Exists/Rate",          "Exists/sec",       @get_exists_rate.process(total["get"]["exists_total"])              if total["get"]["exists_total"]
        report_metric "Get/Missing/Total",        "Missing",          total["get"]["missing_total"]                                       if total["get"]["missing_total"]
        report_metric "Get/Missing/Time",         "Milliseconds",     total["get"]["missing_time_in_millis"]                              if total["get"]["missing_time_in_millis"]
        report_metric "Get/Missing/Rate",         "Missing/sec",      @get_missing_rate.process(total["get"]["missing_total"])            if total["get"]["missing_total"]
      end

      if total["search"]
        report_metric "Search/Query/Total",       "Queries",          total["search"]["query_total"]                                      if total["search"]["query_total"]
        report_metric "Search/Query/Time",        "Milliseconds",     total["search"]["query_time_in_millis"]                             if total["search"]["query_time_in_millis"]
        report_metric "Search/Query/Rate",        "Queries/sec",      @search_query_rate.process(total["search"]["query_total"])          if total["search"]["query_total"]
        report_metric "Search/Fetch/Total",       "Fetches",          total["search"]["fetch_total"]                                      if total["search"]["fetch_total"]
        report_metric "Search/Fetch/Time",        "Milliseconds",     total["search"]["fetch_time_in_millis"]                             if total["search"]["fetch_time_in_millis"]
        report_metric "Search/Fetch/Rate",        "Fetches/sec",      @search_fetch_rate.process(total["search"]["fetch_total"])          if total["search"]["fetch_total"]
      end


    end

    private

    def get_elasticsearch_status
      begin
	  
        u = URI.parse("#{url}/#{index}/_stats")
        r = ::Net::HTTP::Get.new(u.path)
        r.use_ssl = true if u.scheme.casecmp("https") == 0
        r.basic_auth(username, password) unless username.to_s.empty?

        http = ::Net::HTTP.new(u.host, u.port)
        http.open_timeout = 5
        http.read_timeout = 5
        resp = http.request(r)
      rescue Timeout::Error
        print "ERROR while gathering stats from #{url}: connect/read timeout\n"
        return nil
      rescue Exception => e
        print "ERROR while gathering stats from #{url}: #{e.message}\n"
        return nil
      end

      if !resp.is_a?(Net::HTTPSuccess)
        print "ERROR while gathering stats from #{url}: "
        print "#{resp.code} #{resp.message}\n"
        return nil
      end

      if resp.content_type != "application/json"
        print "ERROR while parsing stats from #{url}: Excepted JSON"
        return nil
      end
      return resp.body
    end

 def get_elasticsearch_cluster_status
      begin
	  
        u = URI.parse("#{url}/_cluster/health")
        r = ::Net::HTTP::Get.new(u.path)
        r.use_ssl = true if u.scheme.casecmp("https") == 0
        r.basic_auth(username, password) unless username.to_s.empty?

        http = ::Net::HTTP.new(u.host, u.port)
        http.open_timeout = 5
        http.read_timeout = 5
        resp = http.request(r)
      rescue Timeout::Error
        print "ERROR while gathering stats from #{url}: connect/read timeout\n"
        return nil
      rescue Exception => e
        print "ERROR while gathering stats from #{url}: #{e.message}\n"
        return nil
      end

      if !resp.is_a?(Net::HTTPSuccess)
        print "ERROR while gathering stats from #{url}: "
        print "#{resp.code} #{resp.message}\n"
        return nil
      end

      if resp.content_type != "application/json"
        print "ERROR while parsing stats from #{url}: Excepted JSON"
        return nil
      end
      return resp.body
    end




  end

  NewRelic::Plugin::Config.config_file = File.dirname(__FILE__) + '/config/newrelic_plugin.yml'
  NewRelic::Plugin::Setup.install_agent :elasticsearch_stats_agent, self

  NewRelic::Plugin::Run.setup_and_run
end


